# BERT (Bidrectional Encoder Representation Transformers)
- The first LLM developed by the **Google Research Team**
- Google Search uses **BERT** (We can search a complete english sounding word instead of just a keyword)
- e.g. "What is the financial capital of India?" instead of "Financial Capital India"
- Now with BERT, Google Search captures the important nuance, context, and delivers a significantly improved quality response.

### BERT vs GPT
- GPT (Generative Pre-Trained Transformer) was the first pre-trained model developed by OpenAI.
- GPT was used for fine tuning on various NLP tasks and obtained state-of-art results.
